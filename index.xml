<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Home on Fahim Dalvi</title>
    <link>https://fdalvi.github.io/</link>
    <description>Recent content in Home on Fahim Dalvi</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 05 Feb 2018 22:00:00 +0300</lastBuildDate>
    
	<atom:link href="https://fdalvi.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Projects</title>
      <link>https://fdalvi.github.io/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdalvi.github.io/projects/</guid>
      <description> Live Speech Translation
Bilingual Arabic and English transcription and translation platform with a robust backend enabling live broadcastable sessions
React NodeJS MongoDB Nginx Puppeteer Artillery.io    Machine Translation API
Distributed backend managing multiple machine translation engines built at QCRI and a simple to use user-facing REST API. Served over 400K requests from 30+ countries so far! Python React NodeJS MongoDB Grommet   More to come!   </description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://fdalvi.github.io/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdalvi.github.io/research/</guid>
      <description>2018 Coming soon!
 2017  Neural Machine Translation Training in a Multi-Domain Scenario  Hassan Sajjad, Nadir Durrani, Fahim Dalvi, Yonatan Belinkov, Stephan Vogel   International Workshop on Spoken Language Translation 2017 In this paper, we explore alternative ways to train a neural machine translation system in a multi-domain scenario. We investigate data concatenation (with fine tuning), model stacking (multi-level fine tuning), data selection and weighted ensemble. Our findings show that the best translation quality can be achieved by building an initial system on a concatenation of available out-of-domain data and then fine-tuning it on in-domain data.</description>
    </item>
    
    <item>
      <title>Teaching</title>
      <link>https://fdalvi.github.io/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdalvi.github.io/teaching/</guid>
      <description>Deep Learning for Natural Language Processing Co-Lecturer Universität Duisburg-Essen, 2018 Coming soon!   Deep Learning for Machine Translation Co-Lecturer DGfS Computational Linguistics Fall School, 2017 A 10-lecture crash course in deep learning, specialized towards machine translation. These lectures cover Language Modeling, basics of Machine Learning, Neural Networks, Recurrent Neural Networks and finish with Sequence to Sequence models for Machine translation. We take a look at practical considerations, along with exercises to help solidify the concepts.</description>
    </item>
    
    <item>
      <title>Network throttling in Puppeteer</title>
      <link>https://fdalvi.github.io/blog/2018-02-05-puppeteer-network-throttle/</link>
      <pubDate>Mon, 05 Feb 2018 22:00:00 +0300</pubDate>
      
      <guid>https://fdalvi.github.io/blog/2018-02-05-puppeteer-network-throttle/</guid>
      <description>Puppeteer is an awesome way to run Chrome (or Chromium) in headless mode, i.e. load and interact with web pages without ever visually seeing them.
 Why would this be useful?
A headless browser is a great way to automate testing, even on remote server machines!
 Puppeteer provides a nice interface through Node to script any interactions you can have with a page, like entering input in a textbox, clicking a button and so on.</description>
    </item>
    
    <item>
      <title>15-213: Introduction to Computer Systems</title>
      <link>https://fdalvi.github.io/teaching/2013-15213-computer-systems-cmuq/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdalvi.github.io/teaching/2013-15213-computer-systems-cmuq/</guid>
      <description>As a Teaching Assistant for the course, part of my responsibilities was to prepare and deliver recitations every Thursday. These recitations reviewed the material from the week&amp;rsquo;s lectures, talked about assignments and just generally served as a platform to clear any lingering confusion or doubts. All these slides were created from scratch, but a lot of inspiration was drawn from previous recitations for the same course.
 Week 1: Introduction [slides] Week 2: Floating point representations [slides] Week 3: Introduction to Assembly [slides] [code] Week 4: Assembly continued [slides] [code] Week 5: C Data-structures [slides] [code] Week 6: System Memory management [slides] Week 7: Exam 1 preparation [slides] Week 8: C Signals and UNIX IO [slides] [code] Week 9: Virtual Memory [slides] [code] Week 10: Memory Allocation in C and Debugging tips [slides] Week 11: Exam 2 preparation [slides] Week 12: Proxies [slides] Week 13: Proxies continued and concurrency [slides] [code] Week 14: Final exam review [slides]  Feel free to use the above material for your own courses.</description>
    </item>
    
    <item>
      <title>Deep Learning for Machine Translation</title>
      <link>https://fdalvi.github.io/teaching/2017-dgfs-cl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://fdalvi.github.io/teaching/2017-dgfs-cl/</guid>
      <description>Hassan Sajjad and I were fortunate enough to have the opportunity to teach a deep learning course at the Computation Linguistics school organized by Deutsche Gesellschaft für Sprachwissenschaft. This course is geared towards students with a limited background in deep and machine learning. It walks them through building their very first machine learning model, all the way up to developing a strong intuition behind sequence-to-sequence models, with the material wrapped in the context of language.</description>
    </item>
    
  </channel>
</rss>