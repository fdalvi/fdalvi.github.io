<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Representations on Fahim Dalvi</title>
    <link>https://fdalvi.github.io/tags/representations/</link>
    <description>Recent content in Representations on Fahim Dalvi</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Sat, 07 Apr 2018 20:00:00 +0300</lastBuildDate>
    
	<atom:link href="https://fdalvi.github.io/tags/representations/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>One-Hot layer using Keras Sequential API</title>
      <link>https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/</link>
      <pubDate>Sat, 07 Apr 2018 20:00:00 +0300</pubDate>
      
      <guid>https://fdalvi.github.io/blog/2018-04-07-keras-sequential-onehot/</guid>
      <description>It is quite common to use a One-Hot representation for categorical data in machine learning, for example textual instances in Natural Language Processing tasks. In Keras, the Embedding layer automatically takes inputs with the category indices (such as [5, 3, 1, 5]) and converts them into dense vectors of some length (e.g. 5 â†’ [0.2 1.7 3.2 -7.6 ...]). What actually happens internally is that 5 gets converted to a one-hot vector (like [0 0 0 0 0 1 0 0 .</description>
    </item>
    
  </channel>
</rss>